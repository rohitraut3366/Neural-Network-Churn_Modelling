{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Dataset\n",
    "### Here first step is to collect data and import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"Churn_Modelling.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>9996</td>\n",
       "      <td>15606229</td>\n",
       "      <td>Obijiaku</td>\n",
       "      <td>771</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96270.64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>9997</td>\n",
       "      <td>15569892</td>\n",
       "      <td>Johnstone</td>\n",
       "      <td>516</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>57369.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101699.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>9998</td>\n",
       "      <td>15584532</td>\n",
       "      <td>Liu</td>\n",
       "      <td>709</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42085.58</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>9999</td>\n",
       "      <td>15682355</td>\n",
       "      <td>Sabbatini</td>\n",
       "      <td>772</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>75075.31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92888.52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>10000</td>\n",
       "      <td>15628319</td>\n",
       "      <td>Walker</td>\n",
       "      <td>792</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38190.78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      RowNumber  CustomerId    Surname  CreditScore Geography  Gender  Age  \\\n",
       "0             1    15634602   Hargrave          619    France  Female   42   \n",
       "1             2    15647311       Hill          608     Spain  Female   41   \n",
       "2             3    15619304       Onio          502    France  Female   42   \n",
       "3             4    15701354       Boni          699    France  Female   39   \n",
       "4             5    15737888   Mitchell          850     Spain  Female   43   \n",
       "...         ...         ...        ...          ...       ...     ...  ...   \n",
       "9995       9996    15606229   Obijiaku          771    France    Male   39   \n",
       "9996       9997    15569892  Johnstone          516    France    Male   35   \n",
       "9997       9998    15584532        Liu          709    France  Female   36   \n",
       "9998       9999    15682355  Sabbatini          772   Germany    Male   42   \n",
       "9999      10000    15628319     Walker          792    France  Female   28   \n",
       "\n",
       "      Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0          2       0.00              1          1               1   \n",
       "1          1   83807.86              1          0               1   \n",
       "2          8  159660.80              3          1               0   \n",
       "3          1       0.00              2          0               0   \n",
       "4          2  125510.82              1          1               1   \n",
       "...      ...        ...            ...        ...             ...   \n",
       "9995       5       0.00              2          1               0   \n",
       "9996      10   57369.61              1          1               1   \n",
       "9997       7       0.00              1          0               1   \n",
       "9998       3   75075.31              2          1               0   \n",
       "9999       4  130142.79              1          1               0   \n",
       "\n",
       "      EstimatedSalary  Exited  \n",
       "0           101348.88       1  \n",
       "1           112542.58       0  \n",
       "2           113931.57       1  \n",
       "3            93826.63       0  \n",
       "4            79084.10       0  \n",
       "...               ...     ...  \n",
       "9995         96270.64       0  \n",
       "9996        101699.77       0  \n",
       "9997         42085.58       1  \n",
       "9998         92888.52       1  \n",
       "9999         38190.78       0  \n",
       "\n",
       "[10000 rows x 14 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['RowNumber', 'CustomerId', 'Surname', 'CreditScore', 'Geography',\n",
       "       'Gender', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'HasCrCard',\n",
       "       'IsActiveMember', 'EstimatedSalary', 'Exited'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = dataset['Exited']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset[['CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'HasCrCard',\n",
    "       'IsActiveMember', 'EstimatedSalary']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 8)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step2: Feture Engineering\n",
    "## OneHostEncoding on Geography"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Geo = pd.get_dummies(dataset['Geography'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Germany</th>\n",
       "      <th>Spain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Germany  Spain\n",
       "0           0      0\n",
       "1           0      1\n",
       "2           0      0\n",
       "3           0      0\n",
       "4           0      1\n",
       "...       ...    ...\n",
       "9995        0      0\n",
       "9996        0      0\n",
       "9997        0      0\n",
       "9998        1      0\n",
       "9999        0      0\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Geo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OneHotEncoding Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Gender = pd.get_dummies(dataset['Gender'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Male\n",
       "0        0\n",
       "1        0\n",
       "2        0\n",
       "3        0\n",
       "4        0\n",
       "...    ...\n",
       "9995     1\n",
       "9996     1\n",
       "9997     0\n",
       "9998     1\n",
       "9999     0\n",
       "\n",
       "[10000 rows x 1 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.concat([X,Geo,Gender], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Germany</th>\n",
       "      <th>Spain</th>\n",
       "      <th>Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>771</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96270.64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>516</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>57369.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101699.77</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>709</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42085.58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>772</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>75075.31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92888.52</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>792</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38190.78</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore  Age  Tenure    Balance  NumOfProducts  HasCrCard  \\\n",
       "0             619   42       2       0.00              1          1   \n",
       "1             608   41       1   83807.86              1          0   \n",
       "2             502   42       8  159660.80              3          1   \n",
       "3             699   39       1       0.00              2          0   \n",
       "4             850   43       2  125510.82              1          1   \n",
       "...           ...  ...     ...        ...            ...        ...   \n",
       "9995          771   39       5       0.00              2          1   \n",
       "9996          516   35      10   57369.61              1          1   \n",
       "9997          709   36       7       0.00              1          0   \n",
       "9998          772   42       3   75075.31              2          1   \n",
       "9999          792   28       4  130142.79              1          1   \n",
       "\n",
       "      IsActiveMember  EstimatedSalary  Germany  Spain  Male  \n",
       "0                  1        101348.88        0      0     0  \n",
       "1                  1        112542.58        0      1     0  \n",
       "2                  0        113931.57        0      0     0  \n",
       "3                  0         93826.63        0      0     0  \n",
       "4                  1         79084.10        0      1     0  \n",
       "...              ...              ...      ...    ...   ...  \n",
       "9995               0         96270.64        0      0     1  \n",
       "9996               1        101699.77        0      0     1  \n",
       "9997               1         42085.58        0      0     0  \n",
       "9998               0         92888.52        1      0     1  \n",
       "9999               0         38190.78        0      0     0  \n",
       "\n",
       "[10000 rows x 11 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split the dataset into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.20, random_state=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import sequential Model From Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Dense\n",
    "  Used to add neuron layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Layer\n",
    "#### Neurons=10, input_fetures=11 and activation_function=relu(rectified linear unit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(units=10, activation='relu', input_dim=11))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second Layer\n",
    "#### Neurons=8, activation_funtion = 'relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(units=8, activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To check Model Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 10)                120       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 8)                 88        \n",
      "=================================================================\n",
      "Total params: 208\n",
      "Trainable params: 208\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Layer Three\n",
    "#### units=6 activation='relu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(units=6, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 10)                120       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 8)                 88        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6)                 54        \n",
      "=================================================================\n",
      "Total params: 262\n",
      "Trainable params: 262\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Last Layer\n",
    "#### Units= 1 and activation='sigmoid'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(units=1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'sequential',\n",
       " 'layers': [{'class_name': 'InputLayer',\n",
       "   'config': {'batch_input_shape': (None, 11),\n",
       "    'dtype': 'float32',\n",
       "    'sparse': False,\n",
       "    'ragged': False,\n",
       "    'name': 'dense_input'}},\n",
       "  {'class_name': 'Dense',\n",
       "   'config': {'name': 'dense',\n",
       "    'trainable': True,\n",
       "    'batch_input_shape': (None, 11),\n",
       "    'dtype': 'float32',\n",
       "    'units': 10,\n",
       "    'activation': 'relu',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'GlorotUniform',\n",
       "     'config': {'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None}},\n",
       "  {'class_name': 'Dense',\n",
       "   'config': {'name': 'dense_1',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'units': 8,\n",
       "    'activation': 'relu',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'GlorotUniform',\n",
       "     'config': {'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None}},\n",
       "  {'class_name': 'Dense',\n",
       "   'config': {'name': 'dense_2',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'units': 6,\n",
       "    'activation': 'relu',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'GlorotUniform',\n",
       "     'config': {'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None}},\n",
       "  {'class_name': 'Dense',\n",
       "   'config': {'name': 'dense_3',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'units': 1,\n",
       "    'activation': 'sigmoid',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'GlorotUniform',\n",
       "     'config': {'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None}}]}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 10)                120       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 8)                 88        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6)                 54        \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 7         \n",
      "=================================================================\n",
      "Total params: 269\n",
      "Trainable params: 269\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.00001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.516934  , -0.04073495,  0.19664681,  0.23998845,  0.42411488,\n",
       "         -0.44763753,  0.45498878,  0.32137883,  0.05464631, -0.40650302],\n",
       "        [ 0.21845156,  0.4020657 ,  0.5037516 ,  0.4096058 , -0.08631849,\n",
       "          0.49408358,  0.36419713,  0.00197494,  0.22873074, -0.44990492],\n",
       "        [-0.23349789, -0.05715802,  0.44061708,  0.4101035 ,  0.25148314,\n",
       "         -0.0748615 , -0.1156106 , -0.46702397, -0.12713283, -0.41611993],\n",
       "        [-0.30577606,  0.25698322, -0.10939023, -0.11453792,  0.10239989,\n",
       "         -0.43729752, -0.18739453,  0.06406707, -0.4730571 ,  0.13935894],\n",
       "        [ 0.13764042,  0.04260767, -0.51415795, -0.44896632,  0.0276081 ,\n",
       "          0.3288241 ,  0.43924892,  0.47675437,  0.47702712, -0.528505  ],\n",
       "        [ 0.17030191,  0.17860043,  0.25487137,  0.39801604,  0.18940187,\n",
       "          0.4531818 ,  0.27292007, -0.38608   , -0.16141841, -0.37530047],\n",
       "        [-0.08774441,  0.23522711, -0.46971548,  0.2093767 ,  0.00779235,\n",
       "          0.41418374, -0.40900967,  0.21336621,  0.31284505, -0.09242591],\n",
       "        [ 0.45240456, -0.3982728 , -0.07355511, -0.38574585, -0.4666586 ,\n",
       "         -0.4475525 , -0.18880847,  0.4968353 , -0.14623955,  0.22227871],\n",
       "        [ 0.19984555, -0.3906611 ,  0.47762161,  0.08404839,  0.3343954 ,\n",
       "         -0.04522797, -0.18381843,  0.2754029 ,  0.2511143 ,  0.0418098 ],\n",
       "        [ 0.37613547,  0.5149793 ,  0.39532882,  0.34601283, -0.0662185 ,\n",
       "          0.4568504 ,  0.5107836 , -0.01222378,  0.40215492,  0.13319093],\n",
       "        [-0.03450567,  0.02928716, -0.23073384,  0.30416137, -0.0080421 ,\n",
       "          0.16834795, -0.47234088, -0.21902707,  0.07089621,  0.33683348]],\n",
       "       dtype=float32),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32),\n",
       " array([[ 0.37174463, -0.4457    , -0.2549629 ,  0.17671311, -0.50785935,\n",
       "          0.12945914, -0.10734701, -0.37490717],\n",
       "        [ 0.3698442 , -0.22280058, -0.0186097 ,  0.28034037,  0.4341731 ,\n",
       "         -0.06468564, -0.09809658,  0.2308442 ],\n",
       "        [ 0.09305322,  0.09038728, -0.39187557, -0.26335657,  0.45111024,\n",
       "         -0.40761703,  0.00568485, -0.5716077 ],\n",
       "        [ 0.10924977, -0.45292944,  0.37389266,  0.48262727, -0.26673713,\n",
       "         -0.316241  , -0.55748737, -0.25283632],\n",
       "        [-0.05754018,  0.3326081 , -0.5444244 ,  0.4462812 , -0.05665964,\n",
       "         -0.47310853, -0.26245537, -0.22297525],\n",
       "        [-0.00563294, -0.03589207,  0.17495376,  0.19136947, -0.0480212 ,\n",
       "         -0.45535523, -0.5432873 , -0.14480296],\n",
       "        [ 0.4020928 , -0.32970172, -0.00680023,  0.53298473, -0.3288256 ,\n",
       "         -0.01158446, -0.18143877,  0.18202919],\n",
       "        [-0.56874406,  0.505082  ,  0.49232435,  0.5421723 ,  0.19453162,\n",
       "         -0.51102835,  0.15524268,  0.22128958],\n",
       "        [ 0.11049181,  0.57619786,  0.01300758,  0.56369233, -0.07137382,\n",
       "          0.03991508,  0.05860835, -0.35148197],\n",
       "        [-0.3061714 , -0.05979782, -0.04089266,  0.31042755, -0.07721919,\n",
       "         -0.10155797, -0.16814226, -0.03606129]], dtype=float32),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32),\n",
       " array([[-0.28292397,  0.33095258,  0.07031131,  0.12089533,  0.09885305,\n",
       "          0.21879941],\n",
       "        [-0.6010877 , -0.3146004 , -0.36673495,  0.6524459 , -0.170519  ,\n",
       "          0.41967154],\n",
       "        [-0.24254096, -0.47437847, -0.16422564, -0.186569  , -0.3752879 ,\n",
       "         -0.38308042],\n",
       "        [ 0.08187836, -0.19693628,  0.6196393 , -0.19185114,  0.6289067 ,\n",
       "         -0.25603235],\n",
       "        [-0.3541254 , -0.37969595, -0.14208734,  0.38479853,  0.36442494,\n",
       "         -0.10275537],\n",
       "        [ 0.46792388, -0.4969716 , -0.12285841, -0.6292038 , -0.22816399,\n",
       "         -0.16229364],\n",
       "        [-0.20730805, -0.1650719 ,  0.10279894,  0.02196878, -0.02269894,\n",
       "         -0.21609873],\n",
       "        [ 0.61101913, -0.37270615,  0.5033791 ,  0.2916909 , -0.4678343 ,\n",
       "          0.07871509]], dtype=float32),\n",
       " array([0., 0., 0., 0., 0., 0.], dtype=float32),\n",
       " array([[-0.09172416],\n",
       "        [-0.19847268],\n",
       "        [-0.19538885],\n",
       "        [-0.20494944],\n",
       "        [ 0.01420236],\n",
       "        [ 0.7630123 ]], dtype=float32),\n",
       " array([0.], dtype=float32)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 938.7706\n",
      "Epoch 2/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 882.6556\n",
      "Epoch 3/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 828.7436\n",
      "Epoch 4/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 777.8787\n",
      "Epoch 5/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 729.1872\n",
      "Epoch 6/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 682.3094\n",
      "Epoch 7/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 637.4617\n",
      "Epoch 8/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 594.4140A: 0s - loss: 625.0\n",
      "Epoch 9/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 553.0309\n",
      "Epoch 10/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 513.0161\n",
      "Epoch 11/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 474.3973\n",
      "Epoch 12/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 436.9946\n",
      "Epoch 13/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 400.7943A: 0s - loss: 421.\n",
      "Epoch 14/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 365.8409\n",
      "Epoch 15/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 331.9862\n",
      "Epoch 16/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 299.1024\n",
      "Epoch 17/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 267.1785\n",
      "Epoch 18/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 236.1910\n",
      "Epoch 19/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 206.1388\n",
      "Epoch 20/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 176.9190\n",
      "Epoch 21/200\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 148.4145A: 0s - loss: 1\n",
      "Epoch 22/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 120.4981\n",
      "Epoch 23/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 93.4984\n",
      "Epoch 24/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 78.0079\n",
      "Epoch 25/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 71.7403: 0s - l\n",
      "Epoch 26/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 67.1611\n",
      "Epoch 27/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 63.0419\n",
      "Epoch 28/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 59.0912\n",
      "Epoch 29/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 55.1076\n",
      "Epoch 30/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 51.3235\n",
      "Epoch 31/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 47.7617\n",
      "Epoch 32/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 44.5215\n",
      "Epoch 33/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 41.6447\n",
      "Epoch 34/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 39.0655\n",
      "Epoch 35/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 36.7609\n",
      "Epoch 36/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 34.7759\n",
      "Epoch 37/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 33.1128\n",
      "Epoch 38/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 31.7352\n",
      "Epoch 39/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 30.5465\n",
      "Epoch 40/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 29.4778\n",
      "Epoch 41/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 28.4759\n",
      "Epoch 42/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 27.5205\n",
      "Epoch 43/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 26.5690\n",
      "Epoch 44/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 25.6231\n",
      "Epoch 45/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 24.7718\n",
      "Epoch 46/200\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 23.9508\n",
      "Epoch 47/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 23.1772\n",
      "Epoch 48/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 22.4958\n",
      "Epoch 49/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 21.8548\n",
      "Epoch 50/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 21.2709\n",
      "Epoch 51/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 20.7674\n",
      "Epoch 52/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 20.2839\n",
      "Epoch 53/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 19.8720\n",
      "Epoch 54/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 19.4740\n",
      "Epoch 55/200\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 19.1192\n",
      "Epoch 56/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 18.7489\n",
      "Epoch 57/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 18.4086\n",
      "Epoch 58/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 18.0774\n",
      "Epoch 59/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 17.7187\n",
      "Epoch 60/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 17.3447\n",
      "Epoch 61/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 16.9567\n",
      "Epoch 62/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 16.5959\n",
      "Epoch 63/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 16.1212\n",
      "Epoch 64/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 15.6266\n",
      "Epoch 65/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 15.1104\n",
      "Epoch 66/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 14.6024\n",
      "Epoch 67/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 14.0743\n",
      "Epoch 68/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 13.5140\n",
      "Epoch 69/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 12.9198\n",
      "Epoch 70/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 12.2877\n",
      "Epoch 71/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 11.6396\n",
      "Epoch 72/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 10.9314\n",
      "Epoch 73/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 10.2151\n",
      "Epoch 74/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 9.4927\n",
      "Epoch 75/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 8.8847\n",
      "Epoch 76/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 8.6063\n",
      "Epoch 77/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 8.4566\n",
      "Epoch 78/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 8.3461\n",
      "Epoch 79/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 8.2490\n",
      "Epoch 80/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 8.1658\n",
      "Epoch 81/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 8.0718\n",
      "Epoch 82/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 7.9783\n",
      "Epoch 83/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 7.8830\n",
      "Epoch 84/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 7.7687\n",
      "Epoch 85/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 7.6379\n",
      "Epoch 86/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 7.5209\n",
      "Epoch 87/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 7.3884\n",
      "Epoch 88/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 7.2699\n",
      "Epoch 89/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 7.1441\n",
      "Epoch 90/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 6.9998\n",
      "Epoch 91/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 6.8501\n",
      "Epoch 92/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 6.7138\n",
      "Epoch 93/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 6.5718\n",
      "Epoch 94/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 6.4266\n",
      "Epoch 95/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 6.2752\n",
      "Epoch 96/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 6.1320\n",
      "Epoch 97/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 5.9660\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 5.7937\n",
      "Epoch 99/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 5.6206\n",
      "Epoch 100/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 5.4269\n",
      "Epoch 101/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 5.2158\n",
      "Epoch 102/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 5.0051\n",
      "Epoch 103/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 4.7936\n",
      "Epoch 104/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 4.5855\n",
      "Epoch 105/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 4.3733\n",
      "Epoch 106/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 4.1415\n",
      "Epoch 107/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 3.8964\n",
      "Epoch 108/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 3.6312\n",
      "Epoch 109/200\n",
      "250/250 [==============================] - ETA: 0s - loss: 3.354 - 0s 1ms/step - loss: 3.3621\n",
      "Epoch 110/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 3.1590\n",
      "Epoch 111/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 2.9989\n",
      "Epoch 112/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 2.8576\n",
      "Epoch 113/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 2.7368\n",
      "Epoch 114/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 2.6197\n",
      "Epoch 115/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 2.4977\n",
      "Epoch 116/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 2.4006\n",
      "Epoch 117/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 2.2993\n",
      "Epoch 118/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 2.1993\n",
      "Epoch 119/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 2.0770\n",
      "Epoch 120/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1.9581\n",
      "Epoch 121/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1.8541\n",
      "Epoch 122/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1.7587\n",
      "Epoch 123/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1.6758\n",
      "Epoch 124/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1.6118\n",
      "Epoch 125/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1.5537\n",
      "Epoch 126/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1.4997\n",
      "Epoch 127/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1.4586\n",
      "Epoch 128/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1.4178\n",
      "Epoch 129/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1.3684\n",
      "Epoch 130/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1.3366\n",
      "Epoch 131/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1.3009\n",
      "Epoch 132/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1.2626\n",
      "Epoch 133/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1.2317\n",
      "Epoch 134/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1.1971\n",
      "Epoch 135/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1.1697\n",
      "Epoch 136/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1.1423\n",
      "Epoch 137/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1.1226\n",
      "Epoch 138/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1.0948\n",
      "Epoch 139/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1.0684\n",
      "Epoch 140/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1.0453\n",
      "Epoch 141/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1.0196\n",
      "Epoch 142/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.9995\n",
      "Epoch 143/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.9801\n",
      "Epoch 144/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.9649\n",
      "Epoch 145/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.9461\n",
      "Epoch 146/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.9289\n",
      "Epoch 147/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.9191\n",
      "Epoch 148/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.8943\n",
      "Epoch 149/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.8847\n",
      "Epoch 150/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.8689\n",
      "Epoch 151/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.8547\n",
      "Epoch 152/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.8361\n",
      "Epoch 153/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.8231\n",
      "Epoch 154/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.8084\n",
      "Epoch 155/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.7905\n",
      "Epoch 156/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.7732\n",
      "Epoch 157/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.7605\n",
      "Epoch 158/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.7540\n",
      "Epoch 159/200\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.760 - 0s 1ms/step - loss: 0.7484\n",
      "Epoch 160/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.7320\n",
      "Epoch 161/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.7299\n",
      "Epoch 162/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.7241\n",
      "Epoch 163/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.7197\n",
      "Epoch 164/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.7130\n",
      "Epoch 165/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.7061\n",
      "Epoch 166/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.7043\n",
      "Epoch 167/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.7040\n",
      "Epoch 168/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.6993\n",
      "Epoch 169/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.6957\n",
      "Epoch 170/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.6898\n",
      "Epoch 171/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.6847\n",
      "Epoch 172/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.6850\n",
      "Epoch 173/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.6806\n",
      "Epoch 174/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.6770\n",
      "Epoch 175/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.6719\n",
      "Epoch 176/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.6722\n",
      "Epoch 177/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.6675\n",
      "Epoch 178/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.6660\n",
      "Epoch 179/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.6634\n",
      "Epoch 180/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.6544\n",
      "Epoch 181/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.6592\n",
      "Epoch 182/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.6601\n",
      "Epoch 183/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.6490\n",
      "Epoch 184/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.6506\n",
      "Epoch 185/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.6528\n",
      "Epoch 186/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.6437\n",
      "Epoch 187/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.6425\n",
      "Epoch 188/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.6369\n",
      "Epoch 189/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.6359\n",
      "Epoch 190/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.6310\n",
      "Epoch 191/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.6333\n",
      "Epoch 192/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.6366\n",
      "Epoch 193/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.6224\n",
      "Epoch 194/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.6230\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 195/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.6262\n",
      "Epoch 196/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.6235\n",
      "Epoch 197/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.6291\n",
      "Epoch 198/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.6180\n",
      "Epoch 199/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.6219\n",
      "Epoch 200/200\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.6196\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1be946cf308>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = pd.DataFrame(model.history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>938.770569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>882.655640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>828.743591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>777.878662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>729.187195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>0.623540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>0.629116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>0.618005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>0.621900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>0.619587</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           loss\n",
       "0    938.770569\n",
       "1    882.655640\n",
       "2    828.743591\n",
       "3    777.878662\n",
       "4    729.187195\n",
       "..          ...\n",
       "195    0.623540\n",
       "196    0.629116\n",
       "197    0.618005\n",
       "198    0.621900\n",
       "199    0.619587\n",
       "\n",
       "[200 rows x 1 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.30970538],\n",
       "       [0.20104456],\n",
       "       [0.20572245],\n",
       "       ...,\n",
       "       [0.16678157],\n",
       "       [0.16672221],\n",
       "       [0.12625766]], dtype=float32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
